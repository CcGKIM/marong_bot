from google.generativeai import configure, GenerativeModel
from config.constants import FAQ
from difflib import get_close_matches
from db.db import SessionLocal
from db.db_models import Users, Manittos
from utils.get_week_index import GetWeekIndex
from datetime import datetime
from utils.support_utils import get_notice_channel_content
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.runnables import RunnableLambda
from dotenv import load_dotenv
import os
import asyncio
import json
import discord

dotenv_path = os.path.join(os.path.dirname(__file__), '..', '.env')
load_dotenv(os.path.abspath(dotenv_path))
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

intents = discord.Intents.default()
intents.guilds = True  # âœ… ì´ ì¤„ ê¼­ ì¶”ê°€
intents.message_content = True
intents.members = True
client = discord.Client(intents=intents)

configure(api_key=os.getenv("GEMINI_API_KEY"))
model = GenerativeModel("models/gemini-1.5-flash")

llm = ChatGoogleGenerativeAI(
    model="gemini-1.5-flash",
    temperature=0.7,
    google_api_key=os.getenv("GEMINI_API_KEY")
)

paused_channels: dict[int, float] = {}

def faq_response_func(query: str) -> str:
    if query in FAQ:
        return FAQ[query]
    match = get_close_matches(query, FAQ.keys(), n=1, cutoff=0.6)
    if match:
        return FAQ[match[0]]
    return "FAQì—ì„œ ë‹µë³€ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

def gemini_answer_func(query: str) -> str:
    faq_context = "\n".join([f"- {k}: {v}" for k, v in FAQ.items()])
    prompt = f"""\
ë‹¹ì‹ ì€ ë§ˆë¡±ì˜ ê³ ê°ì„¼í„° AI ì±—ë´‡ì…ë‹ˆë‹¤.

[FAQ]
{faq_context}

[ì§ˆë¬¸]
{query}

[ë‹µë³€]
"""
    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception:
        return "Gemini í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

def this_week_manittee_func(arg_json: str) -> str:
    data = json.loads(arg_json)
    manitto_id = data["manitto_id"]
    group_id = data["group_id"]
    
    base_date = datetime(2025, 1, 6)
    today = datetime.today()
    week_index = GetWeekIndex(today, base_date).get()
    
    with SessionLocal() as session:
        result = (
            session.query(Users.nickname)
            .join(Manittos, Users.id == Manittos.manittee_id)
            .filter(
                Manittos.manitto_id == manitto_id,
                Manittos.week == week_index,
                Manittos.group_id == group_id
            )
            .first()
        )
    if not result:
        return f"ì´ë²ˆ ì£¼({week_index}) ë§ˆë‹ˆë  ë§¤ì¹­ì´ ì—†ìŠµë‹ˆë‹¤."
    return f"ì´ë²ˆ ì£¼({week_index}) ë‹¹ì‹ ì˜ ë§ˆë‹ˆë ëŠ” **{result[0]}** ë‹˜ì…ë‹ˆë‹¤!"

def pause_messaging_func(arg_json: str) -> str:
    data = json.loads(arg_json)
    channel_id = data["channel_id"]
    minutes = data.get("minutes", 1)

    now = asyncio.get_event_loop().time()
    resume_at = now + minutes * 60
    paused_channels[channel_id] = resume_at

    async def _unpause_later():
        await asyncio.sleep(minutes * 60)
        paused_channels.pop(channel_id, None)
    asyncio.create_task(_unpause_later())

    return f"{minutes}ë¶„ ë™ì•ˆ ì‘ë‹µì„ ë©ˆì¶¥ë‹ˆë‹¤."

GUILD_ID = 1373482494497787964  # ì„œë²„ ID

# tools/notice_summary_func.py ë“±ì—ì„œ ì •ì˜í–ˆë‹¤ê³  ê°€ì •
async def notice_summary_func(state: dict) -> dict:
    guild = state.get("guild")  # âœ… ì „ë‹¬ë°›ì€ guild ê°ì²´

    notice_channel_id = 1373910102913847366
    if guild is None:
        print(f"[DEBUG] notice_summary_func: guild is None, channel_id = {notice_channel_id}")
        return {**state, "result": "ğŸ“› ê³µì§€ ë¶„ì„ ì‹¤íŒ¨: ì„œë²„ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

    try:
        channel = guild.get_channel(notice_channel_id)
        if not channel:
            return {**state, "result": "ğŸ“› ê³µì§€ ì±„ë„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
        
        messages = [msg async for msg in channel.history(limit=5)]
        content = "\n".join([f"{m.author.name}: {m.content}" for m in reversed(messages)])
        prompt = f"ë‹¤ìŒì€ ë””ìŠ¤ì½”ë“œ ê³µì§€ì…ë‹ˆë‹¤:\n\n{content}\n\nìš”ì•½í•´ì£¼ì„¸ìš”."
        response = await llm.ainvoke(prompt)
        return {**state, "result": response.content}
    except Exception as e:
        return {**state, "result": f"ğŸ“› ê³µì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}"}

def safe_str_result(fn):
    def wrapper(x):
        print(f"[DEBUG] safe_str_result: input = {x.get('input')}")
        try:
            output = str(fn(x["input"]))
        except Exception as e:
            output = f"â— ì˜¤ë¥˜: {e}"
        return {**x, "result": output}
    return wrapper

graph_nodes = {
    "faq_response": RunnableLambda(safe_str_result(faq_response_func)),
    "gemini_answer": RunnableLambda(safe_str_result(gemini_answer_func)),
    "this_week_manittee": RunnableLambda(safe_str_result(this_week_manittee_func)),
    "pause_messaging": RunnableLambda(safe_str_result(pause_messaging_func)),
    "notice_summary": RunnableLambda(notice_summary_func),
}

__all__ = ["graph_nodes", "paused_channels"]